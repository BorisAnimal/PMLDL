{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "jokes_filepath = os.path.join('data', 'jokes.csv')\n",
    "prep_outpath = os.path.join('data', 'prep', 'gpt2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
      "100   491  100   491    0     0    491      0  0:00:01 --:--:--  0:00:01  1653\n"
     ]
    }
   ],
   "source": [
    "!curl https://raw.githubusercontent.com/Tenoke/gpt-2/small/download_model.sh -o download_model.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "\n",
    "# Linux\n",
    "# !sh download_model.sh 117M\n",
    "\n",
    "# Windows\n",
    "!download_model.sh 117M"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2 48443 14629    14  8800    14 24330 21015    18   198     2 29566\n",
      "    25   198     2   220   350    56  4221  1340 34219    28 10677 24457\n",
      "   268  8189    13  9078  1279  7753    91 34945    91  4743   672    29\n",
      "  1220  6978    14  1462    14 22915    13 37659    89   198     2   220\n",
      "   350    56  4221  1340 34219    28 10677 24457 27432  1377 19608   292\n",
      "   316  1220  6978    14  1462    14 22915    13 37659    89   198   198\n",
      " 11748  2046   198 11748 33918   198 11748 28686   198 11748   299 32152\n",
      "   355 45941   198 11748 11192   273 11125   355 48700   198 11748  4738\n",
      "   198 11748   640   198 11748   256    80 36020   198 11748 15095   198\n",
      "   198 11748  2207 12342   628   198  4299  3440    62 19608   292   316\n",
      "     7 12685    11  3108  2599   198   220   220   220 13532   796 17635\n",
      "   198   220   220   220   611 28686    13  6978    13  4468   576     7\n",
      "  6978  2599   198   220   220   220   220   220   220   220  1303 17427\n",
      "  2393   198   220   220   220   220   220   220   220 13532    13 33295\n",
      "     7  6978     8   198   220   220   220  1288   361 28686    13  6978\n",
      "    13  9409   343     7  6978  2599   198   220   220   220   220   220\n",
      "   220   220  1303 27387   198   220   220   220   220   220   220   220\n",
      "   329   357 15908  6978    11  4808    11   277 14933     8   287 28686\n",
      "    13 11152     7  6978  2599   198   220   220   220   220   220   220\n",
      "   220   220   220   220   220   329   277  3672   287   277 14933    25\n",
      "   198   220   220   220   220   220   220   220   220   220   220   220\n",
      "   220   220   220   220 13532    13 33295     7   418    13  6978    13\n",
      " 22179     7 15908  6978    11   277  3672  4008   198   220   220   220\n",
      "  2073    25   198   220   220   220   220   220   220   220  1303  2195\n",
      "  2454 15095   198   220   220   220   220   220   220   220 13532   796\n",
      " 15095    13  4743   672     7  6978     8   628   220   220   220 11241\n",
      "    62   354 14125   796 17635   198   220   220   220   329  3108   287\n",
      "   256    80 36020    13    83    80 36020     7  6978    82  2599   198\n",
      "   220   220   220   220   220   220   220   351  1280     7  6978    11\n",
      "   705    81 11537   355   277    79    25   198   220   220   220   220\n",
      "   220   220   220   220   220   220   220  8246    62  5239   796   277\n",
      "    79    13   961  3419   198   220   220   220   220   220   220   220\n",
      " 16326   796 45941    13 25558     7 12685    13   268  8189     7  1831\n",
      "    62  5239  4008   198   220   220   220   220   220   220   220 11241\n",
      "    62   354 14125    13 33295     7    83   482   641     8   198   220\n",
      "   220   220  1441 11241    62   354 14125   628   198  4299 37773    62\n",
      " 12417     7   259    62  5239    11   503    62 37659    89    11  2746\n",
      "    62  3672 11639 17657    44     6  2599   198   220   220   220  2207\n",
      "   796  2207 12342    13  1136    62 12685 12342     7 19849    62  3672\n",
      "     8   198   220   220   220  3601 10786 36120  3696 11537   198   220\n",
      "   220   220 22716   796  3440    62 19608   292   316     7 12685    11\n",
      "   287    62  5239     8   198   220   220   220  3601 10786 33874  3256\n",
      "   503    62 37659    89     8   198   220   220   220 45941    13 21928\n",
      "    89    62  5589  2790     7   448    62 37659    89    11  1635   354\n",
      " 14125     8   628   198   361 11593  3672   834  6624   705   834 12417\n",
      "   834 10354   198   220   220   220  2046    13 13543     7   268  8189\n",
      "    62 12417     8   198]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "with np.load('data/prep/gpt2.txt.npz') as data:\n",
    "    print(data['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 38269 entries, 0 to 38268\n",
      "Data columns (total 3 columns):\n",
      "ID          38269 non-null int64\n",
      "Question    38269 non-null object\n",
      "Answer      38269 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 897.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(jokes_filepath)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding(s):\n",
    "#     return re.sub('[\\xc2-\\xf4][\\x80-\\xbf]+',lambda m: m.group(0).encode('latin1').decode('utf8'),s)\n",
    "    return s.encode('latin1', 'ignore').decode('utf8', 'ignore')\n",
    "\n",
    "text_corpus = ''\n",
    "for _, question, answer in data.values:\n",
    "    text_corpus += fix_encoding(f'q: {question}\\na: {answer}\\n')\n",
    "text_corpus += '\\n\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the corresponding folder (if needed)\n",
    "os.makedirs(os.path.dirname(prep_outpath), exist_ok=True)\n",
    "with open(prep_outpath, 'w') as out_file:\n",
    "    out_file.write(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.system(f'python src/encode.py --in-text {prep_outpath} --out-npz {prep_outpath}.npz')\n",
    "\n",
    "!pythonpath.bat src encode.py \"data\\prep\\gpt2.txt\" \"data\\prep\\gpt2.txt.npz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pythonpath.bat src train.py --dataset data\\prep\\gpt2.txt.npz --sample_every=250 --learning_rate=0.0001 --stop_after=251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pythonpath.bat src train.py --dataset data\\prep\\gpt2.txt.npz --sample_every=250 --learning_rate=0.001 --stop_after=751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pythonpath.bat src train.py --dataset data\\prep\\gpt2.txt.npz --sample_every=250 --learning_rate=0.0001 --beta=0.95 --stop_after=1251"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r /content/gpt-2/checkpoint/run1/* /content/gpt-2/models/117M/\n",
    "from distutils.dir_util import copy_tree\n",
    "copy_tree('checkpoint/run1', 'models/run1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python src/interactive_conditional_samples.py --model_name run1 --top_k 5 --temperature 0.9\n",
    "# q: Did you hear about the Native American man that drank 200 cups of tea?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
